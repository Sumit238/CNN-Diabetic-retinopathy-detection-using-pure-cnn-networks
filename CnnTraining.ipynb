{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CnnTraining.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nqvkDUzLFH69"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8RMHULwoyoM",
        "outputId": "0f46c509-b49d-493d-a987-d68cfce7d0bb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlI8DHIyFH6z"
      },
      "source": [
        " %matplotlib inline\n",
        "import os\n",
        "import json\n",
        "import copy\n",
        "import time\n",
        "import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from skimage import io\n",
        "from PIL import Image\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from random import shuffle\n",
        "from torchvision import transforms,datasets, models\n",
        "from torch.utils.data import Dataset\n",
        "from IPython.display import clear_output\n",
        "print(torch.__version__) # This code has been updated for PyTorch 1.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDbk4qHeJQdv"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQTeNTQz1eMD"
      },
      "source": [
        "labelsTable = pd.read_csv('/content/drive/MyDrive/modefied_labels.csv')\n",
        "labelsTable=labelsTable.to_json()\n",
        "labelsTable=json.loads(labelsTable)\n",
        "allLabels={}\n",
        "for row in range(35108):\n",
        "    allLabels[labelsTable['image'][str(row)]]=labelsTable['level'][str(row)]\n",
        "print(allLabels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEupGPpXmOrB"
      },
      "source": [
        "# Preparing train list\n",
        "trainShuffList = os.listdir('/content/drive/MyDrive/trainData')\n",
        "trainLabelShuffList = []\n",
        "for img in trainShuffList:\n",
        "  trainLabelShuffList.append(allLabels[img[:-5]])\n",
        "print(len(trainShuffList))\n",
        "print(len(trainLabelShuffList))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1wmYHsK2qDo"
      },
      "source": [
        "# Preparing test list\n",
        "testShuffList = os.listdir('/content/drive/MyDrive/testData')\n",
        "testLabelShuffList = []\n",
        "for img in testShuffList:\n",
        "  testLabelShuffList.append(allLabels[img[:-5]])\n",
        "print(testShuffList)\n",
        "print(len(testLabelShuffList))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9oaxH4sFH62"
      },
      "source": [
        "## Load Data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDKtQo9_Hyqs"
      },
      "source": [
        "class customDataLoader(Dataset):\n",
        "  def __init__(self,root_dir,labelList,itemList,transforms=None):\n",
        "    self.itemList=itemList\n",
        "    self.labelList=labelList\n",
        "    self.root_dir=root_dir\n",
        "    self.transforms=transforms \n",
        "  def __len__(self):\n",
        "    return len(self.itemList)\n",
        "  def __getitem__(self,index):\n",
        "      img_path=os.path.join(self.root_dir,self.itemList[index-1])\n",
        "      image = Image.open(img_path)\n",
        "      y_label=self.labelList[index-1]\n",
        "      if(self.transforms):\n",
        "        image = self.transforms(image)\n",
        "    \n",
        "      return (image,y_label)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcZAKqI2FH62"
      },
      "source": [
        "trainDir='/content/drive/MyDrive/trainData'\n",
        "testDir='/content/drive/MyDrive/testData'\n",
        "apply_transform = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor()])\n",
        "train_dataset = customDataLoader(trainDir,trainLabelShuffList,trainShuffList,apply_transform)\n",
        "trainLoader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
        "test_dataset = customDataLoader(testDir,testLabelShuffList,testShuffList,apply_transform)\n",
        "testLoader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFR2zBEEFH63"
      },
      "source": [
        "# Size of train and test datasets\n",
        "print('No. of samples in train set: '+str(len(trainLoader.dataset)))\n",
        "print('No. of samples in test set: '+str(len(testLoader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAMEFSBqFH64"
      },
      "source": [
        "## Define network architecture\n",
        "Define your architecture and modify classification/fullyConected output accordingly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZVa8KYYFH65",
        "scrolled": true
      },
      "source": [
        "net = models.resnet18()\n",
        "# Modifying the last fully-connected layer for 10 classes\n",
        "net.fc = nn.Linear(512,5)\n",
        "#print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEHzEHLuhDS2"
      },
      "source": [
        " Change runtime of google colab to gpu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaiDk5leFH67",
        "outputId": "574b1052-ed2c-4edd-8f37-3660f0dfd1fd"
      },
      "source": [
        "# Check availability of GPU\n",
        "use_gpu = torch.cuda.is_available()\n",
        "# use_gpu = False # Uncomment in case of GPU memory error\n",
        "if use_gpu:\n",
        "    print('GPU is available!')\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    print('GPU is not available!')\n",
        "    device = \"cpu\"\n",
        "    \n",
        "net = net.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llLSj6fthx9F"
      },
      "source": [
        "Declare variables to store epoch accuracy and loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz_yMUozN-FM"
      },
      "source": [
        "trainDataTensor=[]\n",
        "testDataTensor=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3mQqo3zR6iP"
      },
      "source": [
        "trainLoss = []\n",
        "trainAuxLoss = []\n",
        "trainTotalLoss = []\n",
        "trainAcc = []\n",
        "testLoss = []\n",
        "testAcc = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqvkDUzLFH69"
      },
      "source": [
        "## Define loss function and optimizer and  Train the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SRxA8776chj"
      },
      "source": [
        "# Testing Input to Network\n",
        "BatchSize=64\n",
        "criterion = nn.NLLLoss() # Negative Log-likelihood\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-5) # Adam\n",
        "\n",
        "for epoch in range(1000):\n",
        "  runningLoss = 0.0   \n",
        "  avgTotalLoss = 0.0\n",
        "  running_correct = 0\n",
        "  net.train()\n",
        "  for data in trainLoader:\n",
        "    try:\n",
        "      trainDataTensor.append(data)\n",
        "      input,labels=data\n",
        "      input=input.to(device)\n",
        "      labels=labels.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      outputs = net(input) \n",
        "      print(outputs,labels)\n",
        "      _, predicted = torch.max(outputs.data, 1)  \n",
        "      print(predicted,labels)\n",
        "      running_correct += (predicted == labels.data).sum()           \n",
        "            # Compute loss/error\n",
        "      #print(labels.size())\n",
        "      loss = criterion(F.log_softmax(outputs,dim=1), labels.to(torch.long))\n",
        "            # Backpropagate loss and compute gradients\n",
        "      loss.backward()\n",
        "            # Update the network parameters\n",
        "      optimizer.step()\n",
        "            # Accumulate loss per batch\n",
        "      runningLoss += loss.item()\n",
        "    except Exception as e:\n",
        "      print(e.message)\n",
        "  print(running_correct)\n",
        "  avgTrainAcc = 100*float(running_correct)/10048\n",
        "  avgTrainLoss = runningLoss/(10048/BatchSize)    \n",
        "  trainAcc.append(avgTrainAcc)\n",
        "  trainLoss.append(avgTrainLoss)\n",
        "  print(epoch,'/',10,'avgTrainAcc:',avgTrainAcc,'avgTrainLoss',avgTrainLoss)\n",
        "\n",
        "  net.eval() # For testing [Affects batch-norm and dropout layers (if any)]\n",
        "  running_correct = 0\n",
        "  with torch.no_grad():\n",
        "      for data in testLoader:\n",
        "          testDataTensor.append(data)\n",
        "          inputs,labels = data\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "          outputs = net(inputs)\n",
        "          \n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          running_correct += (predicted == labels.data).sum()   \n",
        "          loss = criterion(F.log_softmax(outputs,dim=1), labels.to(torch.long))\n",
        "          runningLoss += loss.item() \n",
        "  \n",
        "            \n",
        "  avgTestLoss = runningLoss/(2560/BatchSize)\n",
        "  avgTestAcc = 100*float(running_correct)/2560\n",
        "  print(epoch,'/',10,'avgTestAcc:',avgTestAcc,'avgTrainLoss',avgTestLoss)\n",
        "  testLoss.append(avgTestLoss)\n",
        "  testAcc.append(avgTestAcc)\n",
        "  if(1):\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99Rmr_vJOkg0"
      },
      "source": [
        "# Testing Input to Network\n",
        "BatchSize=64\n",
        "criterion = nn.NLLLoss() # Negative Log-likelihood\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-1) # Adam\n",
        "for epoch in range(1000):\n",
        "  runningLoss = 0.0   \n",
        "  avgTotalLoss = 0.0\n",
        "  running_correct = 0\n",
        "  net.train()\n",
        "  for data in trainDataTensor :\n",
        "    try:\n",
        "      input,labels=data\n",
        "      input=input.to(device)\n",
        "      labels=labels.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      outputs = net(input) \n",
        "      _, predicted = torch.max(outputs.data, 1)  \n",
        "      running_correct += (predicted == labels.data).sum()           \n",
        "            # Compute loss/error\n",
        "      #print(labels.size())\n",
        "      loss = criterion(F.log_softmax(outputs,dim=1), labels.to(torch.long))\n",
        "            # Backpropagate loss and compute gradients\n",
        "      loss.backward()\n",
        "            # Update the network parameters\n",
        "      optimizer.step()\n",
        "            # Accumulate loss per batch\n",
        "      runningLoss += loss.item()\n",
        "      idk+=1\n",
        "    except Exception as e:\n",
        "      print(e.message)\n",
        "  print(running_correct)\n",
        "  avgTrainAcc = 100*float(running_correct)/10048\n",
        "  avgTrainLoss = runningLoss/(10048/BatchSize)    \n",
        "  trainAcc.append(avgTrainAcc)\n",
        "  trainLoss.append(avgTrainLoss)\n",
        "  print(epoch,'/',10,'avgTrainAcc:',avgTrainAcc,'avgTrainLoss',avgTrainLoss)\n",
        "\n",
        "  net.eval() # For testing [Affects batch-norm and dropout layers (if any)]\n",
        "  running_correct = 0\n",
        "  with torch.no_grad():\n",
        "      for data in testDataTensor:\n",
        "          inputs,labels = data\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "          outputs = net(inputs)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          running_correct += (predicted == labels.data).sum()   \n",
        "          loss = criterion(F.log_softmax(outputs,dim=1), labels.to(torch.long))\n",
        "          runningLoss += loss.item() \n",
        "  \n",
        "  avgTestLoss = runningLoss/(2560/BatchSize)\n",
        "  avgTestAcc = 100*float(running_correct)/2560\n",
        "  print(epoch,'/',10,'avgTestAcc:',avgTestAcc,'avgTrainLoss',avgTestLoss)\n",
        "  testLoss.append(avgTestLoss)\n",
        "  testAcc.append(avgTestAcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g18c2yHwFH7B"
      },
      "source": [
        "## Visualization of weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXzoDk4VFH7D"
      },
      "source": [
        "fig1 = plt.figure(1)        \n",
        "plt.plot(range(1000),[i  for i in trainLoss],'r',label='trainloss') \n",
        "plt.plot(range(1000),[i  for i in testLoss],'g',label='testloss')\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.title(\"loss vs epoch\")\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "fig2=plt.figure(2)\n",
        "plt.plot(range(1000),[i  for i in trainAcc],'r',label='trainAcc') \n",
        "plt.plot(range(1000),[i  for i in testAcc],'g',label='testAcc') \n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"Acc\")\n",
        "plt.title(\"Accuracy vs epoch\")\n",
        "plt.legend()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EolmJdQpzz9a"
      },
      "source": [
        "torch.save(net.state_dict(), '/content/drive/MyDrive/dr_trained_model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}